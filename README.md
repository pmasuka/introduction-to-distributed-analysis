# Exercises on Spark Core API

This notebook contains exercises on three different datasets. Solving these exercises using the **Spark Core API **is the goal.

## Setup

### Install PySpark

If you are running this notebook on Google Colab or another environment where PySpark is not pre-installed, execute the following cell to install PySpark:

```python
!pip install pyspark
```

### Download Datasets

Make sure to download the datasets required for the exercises. These datasets will be used throughout the notebook to demonstrate the use of the Spark Core API.

## Useful Documentation

Here are some helpful resources to assist you with the exercises:

- **PySpark Documentation**: Comprehensive documentation for PySpark is available at [PySpark API Documentation](https://spark.apache.org/docs/latest/api/python/index.html).
- **Installing PySpark Locally**: Instructions for installing PySpark on your local machine can be found at [PySpark Installation Guide](https://spark.apache.org/docs/latest/api/python/getting_started/install.html). Note that installing PySpark locally includes a local copy of Spark.
- **Spark Core API Reference**: Detailed documentation for the Spark Core API can be accessed at [Spark Core API Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.html).

## Exercises

The exercises are designed to help you practice and master the Spark Core API. Each exercise involves specific tasks that will guide you through Spark data processing and analysis.
